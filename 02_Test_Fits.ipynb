{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mave_calibration.main import singleFit, prep_data\n",
    "import scipy.stats as spsz\n",
    "from utils.fit_fig import fit_fig\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from mave_calibration.em_opt.constraints import density_constraint_violated\n",
    "from mave_calibration.em_opt.utils import get_sample_weights,constrained_em_iteration,em_iteration,get_likelihood\n",
    "import logging\n",
    "from tqdm.autonotebook import tqdm,trange\n",
    "from sklearn.cluster import KMeans\n",
    "from mave_calibration.skew_normal.fit import fit_skew_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_to_satisfy_density_constraint(component_parameters, xlims):\n",
    "    n_components = len(component_parameters)\n",
    "    rep_failed = False\n",
    "    for compI, compJ in zip(range(0,n_components-1),range(1,n_components)):\n",
    "        if rep_failed:\n",
    "            break\n",
    "        for _ in range(300):\n",
    "            if not density_constraint_violated(\n",
    "                component_parameters[compI], component_parameters[compJ], xlims\n",
    "            ):\n",
    "                break\n",
    "            component_parameters[compI] = [component_parameters[compI][0] - .05 * abs(component_parameters[compI][0]),\n",
    "                                           component_parameters[compI][1],\n",
    "                                           component_parameters[compI][2]]\n",
    "            component_parameters[compJ] = [component_parameters[compJ][0] + .05 * abs(component_parameters[compJ][0]),\n",
    "                                           component_parameters[compJ][1],\n",
    "                                           component_parameters[compJ][2]]\n",
    "\n",
    "        if density_constraint_violated(\n",
    "            component_parameters[compI], component_parameters[compJ], xlims\n",
    "        ):\n",
    "            rep_failed = True\n",
    "            break\n",
    "    if rep_failed:\n",
    "        return [[] for _ in range(n_components)]\n",
    "    assert not density_constraint_violated(\n",
    "        component_parameters[0], component_parameters[1], xlims\n",
    "    )\n",
    "    return component_parameters\n",
    "\n",
    "def single_kmeans_init(X, **kwargs):\n",
    "    \"\"\"\n",
    "    Initialize the parameters of the skew normal mixture model using kmeans and the method of moments\n",
    "\n",
    "    Arguments:\n",
    "    X: np.array (N,): observed instances\n",
    "\n",
    "    Optional Keyword Arguments:\n",
    "    - n_clusters: int: number of clusters to use in kmeans. Default: 2\n",
    "    - kmeans_init: str: initialization method for kmeans. Options: [\"random\", \"k-means++\"]. Default: \"random\"\n",
    "    - skewnorm_init_method: str: method to use for fitting the skew normal distribution. Options: [\"mle\", \"mm\"]. Default: \"mle\"\n",
    "    \"\"\"\n",
    "    repeat = 0\n",
    "    while repeat < 1000:\n",
    "        n_clusters = kwargs.get(\"n_clusters\", 2)\n",
    "        init = kwargs.get(\"kmeans_init\", \"random\")\n",
    "        kmeans = KMeans(n_clusters=n_clusters, init=init)\n",
    "\n",
    "        X = np.array(X).reshape((-1, 1))\n",
    "        kmeans.fit(X)\n",
    "        cluster_assignments = kmeans.predict(X)\n",
    "\n",
    "        component_parameters = []\n",
    "        for i in range(n_clusters):\n",
    "            X_cluster = X[cluster_assignments == i]\n",
    "            loc,scale = sps.norm.fit(X_cluster)\n",
    "            a = np.random.uniform(-.25,.25)\n",
    "            component_parameters.append((a,float(loc),float(scale)))\n",
    "        component_parameters = fix_to_satisfy_density_constraint(component_parameters,(X.min(),X.max()))\n",
    "        if not len(component_parameters[0]):\n",
    "            repeat += 1\n",
    "        else:\n",
    "            return component_parameters, kmeans\n",
    "    raise ValueError(\"Failed to initialize\")\n",
    "\n",
    "def random_init(X, **kwargs):\n",
    "    \"\"\"\n",
    "    Initialize the parameters of the skew normal mixture model using random initialization\n",
    "\n",
    "    Arguments:\n",
    "    X: np.array (N,): observed instances\n",
    "\n",
    "    Optional Keyword Arguments:\n",
    "    - n_clusters: int: number of clusters to use in kmeans. Default: 2\n",
    "    - skewnorm_init_method: str: method to use for fitting the skew normal distribution. Options: [\"mle\", \"mm\"]. Default: \"mle\"\n",
    "    \"\"\"\n",
    "    repeat = 0\n",
    "    while repeat < 1000:\n",
    "        n_clusters = kwargs.get(\"n_clusters\", 2)\n",
    "        component_parameters = []\n",
    "        for i in range(n_clusters):\n",
    "            loc = np.random.uniform(X.min(), X.max())\n",
    "            scale = np.random.uniform(1e-5, X.max() - X.min())\n",
    "            a = np.random.uniform(kwargs.get('skew_min',-5),kwargs.get('skew_max',5))\n",
    "            component_parameters.append((a,loc,scale))\n",
    "        component_parameters = fix_to_satisfy_density_constraint(component_parameters,(X.min(),X.max()))\n",
    "        if not len(component_parameters[0]):\n",
    "            repeat += 1\n",
    "        else:\n",
    "            return component_parameters\n",
    "    raise ValueError(\"Failed to initialize\")\n",
    "\n",
    "def single_fit(observations,sample_indicators,**kwargs):\n",
    "    CONSTRAINED=kwargs.get(\"Constrained\",True)\n",
    "    MAX_N_ITERS = kwargs.get(\"max_iters\", 10000)\n",
    "    verbose = kwargs.get(\"verbose\",True)\n",
    "    xlims= (observations.min(),observations.max())\n",
    "    N_samples = sample_indicators.shape[1]\n",
    "    N_components = 2\n",
    "    W = np.ones((N_samples, N_components)) / N_components\n",
    "    try:\n",
    "        initial_params,kmeans = single_kmeans_init(observations, n_clusters=N_components)\n",
    "    except ValueError:\n",
    "        logging.warning(\"Failed to initialize\")\n",
    "        return dict(component_params=[[] for _ in range(N_components)],\n",
    "                    weights=W,\n",
    "                    likelihoods=[-1 * np.inf])\n",
    "    W = get_sample_weights(observations, sample_indicators, initial_params, W)\n",
    "    history = [dict(component_parameters=initial_params, weights=W)]\n",
    "    # initial likelihood\n",
    "    likelihoods = np.array(\n",
    "        [\n",
    "            get_likelihood(observations, sample_indicators, initial_params, W) / len(sample_indicators),\n",
    "        ]\n",
    "    )\n",
    "    # Check for bad initialization\n",
    "    try:\n",
    "        updated_component_params, updated_weights = (\n",
    "            constrained_em_iteration(observations, sample_indicators, initial_params, W, xlims, iterNum=0)\n",
    "        )\n",
    "    except ZeroDivisionError:\n",
    "        logging.warning(\"ZeroDivisionError\")\n",
    "        return dict(component_params=initial_params, weights=W, likelihoods=[*likelihoods, -1 * np.inf],kmeans=kmeans)\n",
    "    likelihoods = np.array(\n",
    "        [\n",
    "            *likelihoods,\n",
    "            get_likelihood(observations, sample_indicators, updated_component_params, updated_weights)\n",
    "            / len(sample_indicators),\n",
    "        ]\n",
    "    )\n",
    "    # Run the EM algorithm\n",
    "    if verbose:\n",
    "        pbar = tqdm(total=MAX_N_ITERS,leave=False,desc=\"EM Iteration\")\n",
    "    \n",
    "    for i in range(MAX_N_ITERS):\n",
    "        history.append(dict(component_parameters=updated_component_params, weights=updated_weights))\n",
    "        if np.isnan(likelihoods).any():\n",
    "            raise ValueError()\n",
    "        if np.isnan(np.concatenate(updated_component_params)).any():\n",
    "            raise ValueError()\n",
    "        if np.isnan(updated_weights).any():\n",
    "            raise ValueError()\n",
    "        if np.isnan(np.concatenate(updated_component_params)).any():\n",
    "            raise ValueError(f\"NaN in updated component params at iteration {i}\\n{updated_component_params}\")\n",
    "        if np.isnan(updated_weights).any():\n",
    "            raise ValueError(f\"NaN in updated weights at iteration {i}\\n{updated_weights}\")\n",
    "        # observations = np.array([np.random.choice(observation_replicates) for observation_replicates in replicates]).reshape(-1,)\n",
    "        # try:\n",
    "        if CONSTRAINED:\n",
    "            updated_component_params, updated_weights = (\n",
    "                constrained_em_iteration(\n",
    "                    observations,sample_indicators, updated_component_params, updated_weights, xlims, iterNum=i+1,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            updated_component_params, updated_weights = em_iteration(\n",
    "                observations,sample_indicators, updated_component_params, updated_weights\n",
    "            )\n",
    "        likelihoods = np.array(\n",
    "            [\n",
    "                *likelihoods,\n",
    "                get_likelihood(\n",
    "                    observations,sample_indicators, updated_component_params, updated_weights\n",
    "                )\n",
    "                / len(sample_indicators),\n",
    "            ]\n",
    "        )\n",
    "        if kwargs.get(\"verbose\",True):\n",
    "            pbar.set_postfix({\"likelihood\": f\"{likelihoods[-1]:.6f}\"})\n",
    "            pbar.update(1)\n",
    "        if kwargs.get('early_stopping',True) and i >= 1 and (np.abs(likelihoods[-1] - likelihoods[-2]) < 1e-10).all():\n",
    "            break\n",
    "    history.append(dict(component_parameters=updated_component_params, weights=updated_weights))\n",
    "    if kwargs.get(\"verbose\",True):\n",
    "        pbar.close()\n",
    "    if CONSTRAINED:\n",
    "        assert not density_constraint_violated(\n",
    "            updated_component_params[0], updated_component_params[1], xlims\n",
    "        )\n",
    "        \n",
    "    return dict(component_params=updated_component_params, weights=updated_weights, likelihoods=likelihoods, history=history,kmeans=kmeans)\n",
    "\n",
    "\n",
    "def fit(observations,sample_indicators,**kwargs):\n",
    "    fits = []\n",
    "    LLs = []\n",
    "    n_fits = kwargs.get(\"n_fits\",1)\n",
    "    with tqdm(total=n_fits,desc=\"Fitting\",leave=False) as pbar:\n",
    "        for i in range(n_fits):\n",
    "            bootstrap_sample_indices = [np.random.choice(np.where(sample_i)[0],\n",
    "                                                         sample_i.sum(),\n",
    "                                                         replace=True) for sample_i in sample_indicators.T]\n",
    "            indices = np.concatenate(bootstrap_sample_indices)\n",
    "            iter_fit = single_fit(observations[indices],sample_indicators[indices],**kwargs)\n",
    "            if not len(iter_fit['component_params'][0]):\n",
    "                continue\n",
    "            fits.append(iter_fit)\n",
    "            LLs.append(get_likelihood(observations,\n",
    "                                      sample_indicators,\n",
    "                                      iter_fit['component_params'],\n",
    "                                      iter_fit['weights'])/len(observations))\n",
    "            llmax = max(LLs)\n",
    "            pbar.set_description(f\"Best LL: {llmax}\")\n",
    "            pbar.update(1)\n",
    "    \n",
    "    model_order = np.argsort(LLs)[::-1]\n",
    "    return fits[model_order[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "def showFit(X,S,component_params, weights,labels):\n",
    "    rng = np.linspace(X.min(),X.max(),5000)\n",
    "    fig,ax = plt.subplots(S.shape[1],1,figsize=(8,3*S.shape[1]),sharex=True,sharey=False)\n",
    "    f = sps.skewnorm.pdf(rng,component_params[0][0],\n",
    "                        loc=component_params[0][1],\n",
    "                        scale=component_params[0][2])\n",
    "    g = sps.skewnorm.pdf(rng,component_params[1][0],\n",
    "                    loc=component_params[1][1],\n",
    "                    scale=component_params[1][2])\n",
    "    for sampleNum in range(S.shape[1]):\n",
    "        ax[sampleNum].hist(X[S[:,sampleNum]],bins=15,density=True)\n",
    "        \n",
    "        ax[sampleNum].plot(rng,weights[sampleNum,0] * f,linestyle='--',color='red')\n",
    "        ax[sampleNum].plot(rng,weights[sampleNum,1] * g,linestyle='--',color='blue')\n",
    "        ax[sampleNum].plot(rng,weights[sampleNum,0] * f+weights[sampleNum,1] *g,alpha=.5,color='green')\n",
    "        ax[sampleNum].set_title(f\"{labels[sampleNum]} (n={S[:,sampleNum].sum()})\")\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Users/danielzeiberg/Desktop/processed_datasets/\")\n",
    "fits = defaultdict(list)\n",
    "data_files = list(data_dir.glob(\"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec8d3a96d3e4e75932179b1e461a4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dcec221a154d87b4a14b857b5e954d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n",
      "/Users/danielzeiberg/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/skew_normal/density_utils.py:34: RuntimeWarning: divide by zero encountered in log\n",
      "  numerators = log_pdfs + np.log(individual_sample_weights)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m datafile\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m observations, sample_indicators, labels, bootstrap_indices \u001b[38;5;241m=\u001b[39m prep_data(datafile)\n\u001b[0;32m----> 7\u001b[0m dataset_fit \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_indicators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mConstrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mn_fits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m fits[dataset_name]\u001b[38;5;241m.\u001b[39mappend(dataset_fit)\n\u001b[1;32m     14\u001b[0m fig,ax \u001b[38;5;241m=\u001b[39m showFit(observations,sample_indicators,\n\u001b[1;32m     15\u001b[0m     dataset_fit[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomponent_params\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     16\u001b[0m     dataset_fit[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m],labels)\n",
      "Cell \u001b[0;32mIn[7], line 194\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(observations, sample_indicators, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m bootstrap_sample_indices \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39mwhere(sample_i)[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    191\u001b[0m                                              sample_i\u001b[38;5;241m.\u001b[39msum(),\n\u001b[1;32m    192\u001b[0m                                              replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m sample_i \u001b[38;5;129;01min\u001b[39;00m sample_indicators\u001b[38;5;241m.\u001b[39mT]\n\u001b[1;32m    193\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(bootstrap_sample_indices)\n\u001b[0;32m--> 194\u001b[0m iter_fit \u001b[38;5;241m=\u001b[39m \u001b[43msingle_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_indicators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iter_fit[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomponent_params\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 151\u001b[0m, in \u001b[0;36msingle_fit\u001b[0;34m(observations, sample_indicators, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# observations = np.array([np.random.choice(observation_replicates) for observation_replicates in replicates]).reshape(-1,)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CONSTRAINED:\n\u001b[1;32m    150\u001b[0m     updated_component_params, updated_weights \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 151\u001b[0m         \u001b[43mconstrained_em_iteration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_indicators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_component_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterNum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     updated_component_params, updated_weights \u001b[38;5;241m=\u001b[39m em_iteration(\n\u001b[1;32m    157\u001b[0m         observations,sample_indicators, updated_component_params, updated_weights\n\u001b[1;32m    158\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/em_opt/utils.py:205\u001b[0m, in \u001b[0;36mconstrained_em_iteration\u001b[0;34m(observations, sample_indicators, current_component_params, current_weights, xlims, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     bsearch_params \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mcurrent_component_params]\n\u001b[0;32m--> 205\u001b[0m constrained_updated_loc \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdated_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbsearch_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlims\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloc_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcomponent_num\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m iter \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterNum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m updated_Delta \u001b[38;5;241m=\u001b[39m get_Delta_update(\n\u001b[1;32m    209\u001b[0m     constrained_updated_loc,\n\u001b[1;32m    210\u001b[0m     observations,\n\u001b[1;32m    211\u001b[0m     responsibilities[component_num],\n\u001b[1;32m    212\u001b[0m     curr_comp_params,\n\u001b[1;32m    213\u001b[0m )\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m component_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/em_opt/utils.py:98\u001b[0m, in \u001b[0;36mbinary_search\u001b[0;34m(candidate_value, current_params, component_index, parameter_index, xlims, msg)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary_search\u001b[39m(\n\u001b[1;32m     83\u001b[0m     candidate_value, current_params, component_index, parameter_index, xlims,msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m ):\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Perform a binary search to find the value of the parameter that satisfies the density constraint\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    float : updated parameter value\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mdensity_constraint_violated\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlims\u001b[49m\u001b[43m)\u001b[49m,msg\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcurrent_params[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcurrent_params[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     current_alternate_params \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28mlist\u001b[39m(density_utils\u001b[38;5;241m.\u001b[39mcanonical_to_alternate(\u001b[38;5;241m*\u001b[39mparam)) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m current_params\n\u001b[1;32m    102\u001b[0m     ]\n\u001b[1;32m    103\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m current_alternate_params[component_index][parameter_index]\n",
      "File \u001b[0;32m~/Documents/research/mave_calibration/src/mave_calibration/mave_calibration/em_opt/constraints.py:18\u001b[0m, in \u001b[0;36mdensity_constraint_violated\u001b[0;34m(params_1, params_2, xlims)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdensity_constraint_violated\u001b[39m(params_1, params_2, xlims):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Check if the density ratio of distribution 1 to distribution 2 is monotonic\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    bool : True if the density ratio is not monotonic (constraint violated), False otherwise\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     log_pdf_1 \u001b[38;5;241m=\u001b[39m sps\u001b[38;5;241m.\u001b[39mskewnorm\u001b[38;5;241m.\u001b[39mlogpdf(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxlims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39mparams_1)\n\u001b[1;32m     19\u001b[0m     log_pdf_2 \u001b[38;5;241m=\u001b[39m sps\u001b[38;5;241m.\u001b[39mskewnorm\u001b[38;5;241m.\u001b[39mlogpdf(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m*\u001b[39mxlims, \u001b[38;5;241m1000\u001b[39m), \u001b[38;5;241m*\u001b[39mparams_2)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39mdiff(log_pdf_1 \u001b[38;5;241m-\u001b[39m log_pdf_2) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mave/lib/python3.10/site-packages/numpy/_core/function_base.py:183\u001b[0m, in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis, device)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endpoint \u001b[38;5;129;01mand\u001b[39;00m num \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    181\u001b[0m     y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    184\u001b[0m     y \u001b[38;5;241m=\u001b[39m _nx\u001b[38;5;241m.\u001b[39mmoveaxis(y, \u001b[38;5;241m0\u001b[39m, axis)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m integer_dtype:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "savedir = Path('/Users/danielzeiberg/Desktop/testfits')\n",
    "savedir.mkdir(exist_ok=True,parents=True)\n",
    "for iteration in trange(10):\n",
    "    for datafile in data_files:\n",
    "        dataset_name = datafile.stem.split(\"_pipeline\")[0]\n",
    "        observations, sample_indicators, labels, bootstrap_indices = prep_data(datafile)\n",
    "        dataset_fit = fit(observations.ravel(), sample_indicators,\n",
    "                          Constrained=True,\n",
    "                          verbose=False,\n",
    "                          max_iters=10000,\n",
    "                          n_fits=10,\n",
    "                          early_stopping=True)\n",
    "        fits[dataset_name].append(dataset_fit)\n",
    "        fig,ax = showFit(observations,sample_indicators,\n",
    "            dataset_fit['component_params'],\n",
    "            dataset_fit['weights'],labels)\n",
    "        fig.savefig(savedir / f\"{dataset_name}_{iteration+1}.png\",bbox_inches='tight',dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mave_calibration.skew_normal.density_utils import joint_densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = [fit(observations,sample_indicators,Constrained=True,verbose=True) for iteration in tqdm(range(100),desc=\"Iterations\",total=100)]\n",
    "# from joblib import Parallel, delayed\n",
    "# results = Parallel(n_jobs=100,verbose=100)(delayed(fit)(observations,sample_indicators,Constrained=True,verbose=False) for iteration in range(1000))\n",
    "result = fit(observations,sample_indicators,\n",
    "               Constrained=True,\n",
    "               verbose=True,\n",
    "               max_iters=10000,\n",
    "               n_fits=10,\n",
    "               early_stopping=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result['kmeans'].cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['history'][0]['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "showFit(observations,sample_indicators,\n",
    "        result['history'][0]['component_parameters'],\n",
    "        result['history'][0]['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showFit(observations,sample_indicators,\n",
    "        result['history'][-1]['component_parameters'],\n",
    "        result['history'][-1]['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mave",
   "language": "python",
   "name": "mave"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
